{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100b64bb-d38b-48b2-9d90-5b14d21f4fd6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dad5a-e389-4259-9447-b2a72e8538e1",
   "metadata": {},
   "source": [
    "This custom data validation tool was created for a specific client to validate their incoming data. \n",
    "\n",
    "The purpose of this validator is to highlight the errors inside the provided by the client data that will prevent its use.\n",
    "\n",
    "This data validator does not fix any issues inside the data since it's not the purpose of this tool. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096d972-b481-409f-ab8a-268e4030688a",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "- [Introduction](#Introduction)\n",
    "- [Library Imports](#Imports)\n",
    "- [Data Upload](#data-loading)\n",
    "- [Technical Validation](#Technical-Validation).\n",
    "  - [Catalog](#Catalog)\n",
    "    - [Catalog Mandatory Columns](#Catalog-Mandatory-Columns)\n",
    "    - [Catalog Data type check](#Catalog-Data-type-check)\n",
    "    - [Catalog Missing values check](#Catalog-Missing-values-check)\n",
    "    - [Catalog Numeric values range check](#Catalog-Numeric-values-range-check)\n",
    "  - [Inventory](#Inventory)\n",
    "    - [Inventory Mandatory Columns](#Inventory-Mandatory-Columns)\n",
    "    - [Inventory Data type check](#Inventory-Data-type-check)\n",
    "    - [Inventory Missing values check](#Inventory-Missing-values-check)\n",
    "    - [Inventory Numeric values range check](#Inventory-Numeric-values-range-check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e55f25-2bc9-48c3-ae0b-58d461a54ca0",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80dcd34e-eae7-43a9-a0f0-c47ef3e78d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9201c6e-1702-4cfa-8b1a-72e630f9cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set color\n",
    "red_color = '\\033[91m'\n",
    "green_color = '\\033[92m'\n",
    "reset_color = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb42b2b-0d0d-4753-8863-9ebbc256f22f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195c76a-0590-42e4-a05c-098e6af9596e",
   "metadata": {},
   "source": [
    "# Data Upload\n",
    "\n",
    "In the data folder should exist 4 files:\n",
    "\n",
    "catalog - a file that contains all information about the inventory\n",
    "\n",
    "inventory - a file that contains the current inventory status of location-inventory\n",
    "\n",
    "location - a file that contains all information about the location\n",
    "\n",
    "transactions - a file that contains all information about all transactions (location-inventory based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c03682-7f2c-4afc-99f1-af938419529b",
   "metadata": {},
   "source": [
    "Every file should contain a specific set of mandatory collumns, other wise the data validator will stop at the stage of data upload.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c17a1a-f522-4e3b-8ab5-01b39143fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of the input files\n",
    "catalog_file_name = 'catalog.csv'\n",
    "inventory_file_name = 'inventory.csv'\n",
    "locations_file_name = 'locations.csv'\n",
    "transactions_file_name = 'transactions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746e4d76-31fd-4c84-92d7-3f4306880f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_file_name\n",
    "\n",
    "df_catalog = pd.read_csv('data/' + catalog_file_name,\n",
    "                        dtype={\n",
    "                                'id': 'str',\n",
    "                                'name': 'str', \n",
    "                                'product_id': 'str'\n",
    "                            })\n",
    "df_inventory = pd.read_csv('data/' + inventory_file_name, \n",
    "                            dtype={\n",
    "                                'location_id': 'str', \n",
    "                                'sku_id': 'str',\n",
    "                                'source_location_id':'str'\n",
    "                             })\n",
    "df_locations = pd.read_csv('data/' + locations_file_name, \n",
    "                            dtype={\n",
    "                                'id': 'str',\n",
    "                                'name': 'str',\n",
    "                                'type': 'str'\n",
    "                             })\n",
    "df_transactions = pd.read_csv('data/' + transactions_file_name, \n",
    "                               dtype={\n",
    "                                   'location_id': 'str', \n",
    "                                   'sku_id': 'str',\n",
    "                                   'source_location_id':'str',\n",
    "                                   'target_location_id': 'str'\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0eebf9-2aa2-417c-a17a-b306bfcca999",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545f68a-738c-4e08-9eb1-6009c7f888ab",
   "metadata": {},
   "source": [
    "# Technical Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005eb17-0f31-46cc-bcb3-8c1f22a02523",
   "metadata": {},
   "source": [
    "## Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95c903-8183-457f-b68f-95690b45d863",
   "metadata": {},
   "source": [
    "### Catalog Mandatory Columns\n",
    "\n",
    "Checking that all the mandator columns are present, columns - **[id,name,product_id,price,cost]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f898c4-f5da-4e89-8e22-e104af559790",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_column_list = ['id','name','product_id','price','cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac80685-a993-4545-8815-53e2f61141b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll columns are present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in catalog_column_list:\n",
    "    assert column in df_catalog.columns, f'{column} column is missing from the catalog file' \n",
    "print(green_color + 'All columns are present.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb78ce6-1f89-4955-898a-1b4e80d4b089",
   "metadata": {},
   "source": [
    "### Catalog Data type check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7985aa3-8e6b-49bb-8ca2-72654c2b71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Dtypes of mandator columns\n",
    "catalog_columns_dtype = {'id':'str','name':'str','product_id':'str','price':'float','cost':'float'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3226f27-e431-45c1-bc99-6e706dabc5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalog['id'].dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f772f8-a98f-41e4-8c14-079121a9b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column, dtype in catalog_columns_dtype.items():\n",
    "    if df_catalog[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_catalog[column] = df_catalog[column].astype('str')\n",
    "        except ValueError:\n",
    "            raise ValueError(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    else:\n",
    "        try:\n",
    "            pd.to_numeric(df_catalog[column], errors='raise', downcast=dtype)\n",
    "        except (TypeError, ValueError):\n",
    "            print(red_color + f\"{column} column has dtype mismatch with {dtype}\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73a014-1107-4657-ab5f-18108e0fc9c2",
   "metadata": {},
   "source": [
    "### Catalog Missing values check\n",
    "\n",
    "Checks if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c032781-8a51-4a24-b33b-97bd69df10ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is populated with data\u001b[0m\n",
      "\u001b[92mname column is populated with data\u001b[0m\n",
      "\u001b[92mproduct_id column is populated with data\u001b[0m\n",
      "\u001b[92mprice column is populated with data\u001b[0m\n",
      "\u001b[92mcost column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in catalog_column_list:\n",
    "    try:\n",
    "        assert df_catalog[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4522751-b9b2-4634-ab9f-800f44d8f6d6",
   "metadata": {},
   "source": [
    "### Catalog Numeric values range check\n",
    "\n",
    "Checks if the values in the column are in expected range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8d4276a-a07a-4b50-92e1-0409a80e1ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll is good, Price is >= 0\u001b[0m\n",
      "\u001b[91mThe Price column contains non-numeric values\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_catalog['price'] >= 0).all()\n",
    "    print(green_color + 'All is good, Price is >= 0' + reset_color)\n",
    "except AssertionError:\n",
    "    print(red_color + 'Price contains values less than 0' + reset_color)\n",
    "    total_count = len(df_catalog['price'])\n",
    "    negative_count = (df_catalog['price'] < 0).sum()\n",
    "    percentage = (negative_count / total_count) * 100\n",
    "    print(red_color + f\"Percentage of price values less than 0: {percentage}%\" + reset_color)\n",
    "\n",
    "try:\n",
    "    assert np.issubdtype(df_catalog['price'].dtype, np.floating) or np.issubdtype(df_catalog['price'].dtype, np.integer)\n",
    "    print(green_color + 'All is good, delimiters in the Price column are in expected range' + red_color)\n",
    "except:\n",
    "    print(red_color + 'The Price column contains non-numeric values' + reset_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c83ac19-09cb-4d85-835a-dccb166bda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll is good, Cost is >= then 0\u001b[0m\n",
      "\u001b[91mThe Cost column contains non-numeric values\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_catalog['cost'] >= 0).all()\n",
    "    print(green_color + 'All is good, Cost is >= then 0' + reset_color)\n",
    "except:\n",
    "    print(red_color + 'Cost contains values less than 0' + reset_color)\n",
    "    total_count = len(df_catalog['cost'])\n",
    "    negative_count = (df_catalog['cost'] < 0).sum()\n",
    "    percentage = (negative_count / total_count) * 100\n",
    "    print(red_color + f\"Percentage of cost values less than 0: {percentage}%\" + reset_color)\n",
    "\n",
    "try:\n",
    "    assert np.issubdtype(df_catalog['cost'].dtype, np.floating) or np.issubdtype(df_catalog['cost'].dtype, np.integer)\n",
    "    print(green_color + 'All is good, delimiters in the Cost column are in expected range' + reset_color)\n",
    "except:\n",
    "    print(red_color + 'The Cost column contains non-numeric values' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9357a4-3aa1-480c-8420-6096cca2737a",
   "metadata": {},
   "source": [
    "## Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb2899-cb63-4f2e-b4d7-f7bb3f609862",
   "metadata": {},
   "source": [
    "### Inventory Mandatory Columns\n",
    "\n",
    "Checking that all the mandator columns are present, columns - **[location_id,sku_id,source_location_id,transit_qty,site_qty,status_date]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eec9655-da26-42d4-b9d1-232647f70854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns list\n",
    "inventory_column_list = ['location_id','sku_id','source_location_id','transit_qty','site_qty','status_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716a2062-97f2-4482-8fe1-b057c568ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mlocation_id column is present.\u001b[0m\n",
      "\u001b[92msku_id column is present.\u001b[0m\n",
      "\u001b[92msource_location_id column is present.\u001b[0m\n",
      "\u001b[92mtransit_qty column is present.\u001b[0m\n",
      "\u001b[92msite_qty column is present.\u001b[0m\n",
      "\u001b[92mstatus_date column is present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in inventory_column_list:\n",
    "    try:\n",
    "        assert column in df_inventory.columns\n",
    "        print(green_color + f'{column} column is present.' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'{column} column is missing from the inventory file'  + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac02c53-3a38-4e3b-af49-13ffff178822",
   "metadata": {},
   "source": [
    "### Inventory Data type check\n",
    "\n",
    "Checks if the column can be transformed into the data type that the system expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d267974f-83dc-42ce-b8e1-721af915601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Dtypes of mandator columns\n",
    "inventory_columns_dtype = {'location_id':'str',\n",
    "                           'sku_id':'str',\n",
    "                           'source_location_id':'uuid',\n",
    "                           'transit_qty':'float',\n",
    "                           'site_qty':'float',\n",
    "                           'status_date':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4800c0f-6af7-4799-b0e5-384165e56e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mEach status_date, sku_id, and location_id has only one unique source_location_id.\u001b[0m\n",
      "\u001b[91mstatus_date column has dtype mismatch with timestamp\u001b[0m\n",
      "\u001b[92mAll dtypes are matching the requirements\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in inventory_columns_dtype.items():\n",
    "    if dtype == 'timestamp':\n",
    "        try:\n",
    "            pd.to_datetime(df_inventory[column], format='ISO8601', errors='raise')\n",
    "        except (TypeError, ValueError):\n",
    "            print(red_color + f\"{column} column has dtype mismatch with {dtype}\" + reset_color)\n",
    "    elif df_inventory[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_inventory[column] = df_inventory[column].astype('str')\n",
    "        except ValueError:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    elif df_inventory[column].dtype == 'int' and dtype == 'float':\n",
    "        try:\n",
    "            df_inventory[column] = df_inventory[column].astype('float')\n",
    "        except ValueError:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    elif dtype == 'uuid':\n",
    "        grouped = df_inventory.groupby(['status_date', 'sku_id', 'location_id'])['source_location_id'].nunique()\n",
    "        if (grouped > 1).any():\n",
    "            print(red_color + \"Multiple unique source_location_id found for the same status_date, sku_id, and location_id.\" + reset_color)\n",
    "        else:\n",
    "            print(green_color + \"Each status_date, sku_id, and location_id has only one unique source_location_id.\" + reset_color)\n",
    "        \n",
    "print(green_color + 'All dtypes are matching the requirements' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5847c4-f89a-4123-bb76-45c779336a1a",
   "metadata": {},
   "source": [
    "### Inventory Missing values check\n",
    "\n",
    "Checks if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bd9df89-8121-477f-9d88-0a0001831867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mlocation_id column is populated with data\u001b[0m\n",
      "\u001b[92msku_id column is populated with data\u001b[0m\n",
      "\u001b[92msource_location_id column is populated with data\u001b[0m\n",
      "\u001b[92mtransit_qty column is populated with data\u001b[0m\n",
      "\u001b[92msite_qty column is populated with data\u001b[0m\n",
      "\u001b[92mstatus_date column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in inventory_column_list:\n",
    "    try:\n",
    "        assert df_inventory[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2073bf2-4673-4c59-af36-2e3a2171a7b0",
   "metadata": {},
   "source": [
    "### Inventory Numeric values range check\n",
    "\n",
    "Checks if the values in the column are in the expected range. transit_qty and site_qty can be less then 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1eb312-8240-4993-beb8-afe4c8335c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mThere is no negative transit_qty\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert df_inventory['transit_qty'].min() >= 0\n",
    "    print(green_color + f'There is no negative transit_qty' + reset_color)\n",
    "except:\n",
    "    print(red_color + f'There is negative transit_qty for some inventories' + reset_color)\n",
    "    print(df_inventory[df_inventory['transit_qty']<0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790359e9-2258-4a32-8168-7292f64823d7",
   "metadata": {},
   "source": [
    "## Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee4d66-893c-4625-bda4-0b638f026067",
   "metadata": {},
   "source": [
    "Checking that all the mandator columns are present, columns - [id,name,type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f904c0d7-c350-4e12-a6ed-28956bdb14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_column_list = ['id','name','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62bbb4ac-5dc7-4de3-b6c3-d216d0d5600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is present.\u001b[0m\n",
      "\u001b[92mname column is present.\u001b[0m\n",
      "\u001b[92mtype column is present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in locations_column_list:\n",
    "    try:\n",
    "        assert column in df_locations.columns\n",
    "        print(green_color + f'{column} column is present.' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'{column} column is missing from the locations file' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d74320-9ac5-40ce-97ed-7ace23544bfe",
   "metadata": {},
   "source": [
    "### Dtype check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a58f1d0-7bbe-4c5c-b5fa-ee201cdb428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Dtypes of mandator columns\n",
    "locations_columns_dtype = {'id':'str',\n",
    "                           'name':'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a63a4fe-a1e9-4870-b527-34a8dafefaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column dtype is matching the requirements\u001b[0m\n",
      "\u001b[92mname column dtype is matching the requirements\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in locations_columns_dtype.items():\n",
    "    if df_locations[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_locations[column] = df_locations[column].astype('str')\n",
    "            print(green_color + f'{column} column dtype is matching the requirements' + reset_color)\n",
    "        except ValueError:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017dd4c9-eb01-483f-b186-4b26293e2837",
   "metadata": {},
   "source": [
    "### Missing values check\n",
    "\n",
    "Check if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "186c7931-df14-41fc-a6ca-7e0883407123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is populated with data\u001b[0m\n",
      "\u001b[92mname column is populated with data\u001b[0m\n",
      "\u001b[92mtype column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in locations_column_list:\n",
    "    try:\n",
    "        assert df_locations[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7ef17-1372-4ca8-a3a7-d015392903b4",
   "metadata": {},
   "source": [
    "### Enum validation\n",
    "\n",
    "Checks if the location types are in expected range of values. Expected types: ['store', 'warehouse', 'vwarehouse','ecommerce', 'plant', 'supplier','outlet', 'unknown', 'client']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c764cea4-b565-40bf-9778-d201cc08e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mWrong location type in column: type\u001b[0m\n",
      "\u001b[91mInvalid location types: ['Shop' 'Warehouse' 'Warehouse ']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "locations_type_enum = ['store', 'warehouse', 'vwarehouse','ecommerce', 'plant', 'supplier', 'outlet', 'unknown', 'client']\n",
    "try:\n",
    "    assert df_locations['type'].isin(locations_type_enum).all()\n",
    "    print(green_color + 'All location types are correct' + reset_color)\n",
    "except:\n",
    "    invalid_types = df_locations[~df_locations['type'].isin(locations_type_enum)]\n",
    "    print(red_color + f\"Wrong location type in column: {column}\" + reset_color)\n",
    "    print(red_color + f\"Invalid location types: {invalid_types['type'].unique()}\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbad530-a592-4e7a-ba5f-58d1f7925662",
   "metadata": {},
   "source": [
    "### Transactions\n",
    "\n",
    "Checking that all the mandator columns are present, columns - ['id','sku_id','source_location_id','target_location_id','quantity','type','transaction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c64528-e167-46b0-98fc-2ae10d21b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_column_list = ['id','sku_id','source_location_id','target_location_id','quantity',\n",
    "                            'type','transaction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d56f0c2-7339-4b11-b410-7e20dadddecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is present.\u001b[0m\n",
      "\u001b[92msku_id column is present.\u001b[0m\n",
      "\u001b[92msource_location_id column is present.\u001b[0m\n",
      "\u001b[92mtarget_location_id column is present.\u001b[0m\n",
      "\u001b[92mquantity column is present.\u001b[0m\n",
      "\u001b[92mtype column is present.\u001b[0m\n",
      "\u001b[92mtransaction_date column is present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in transactions_column_list:\n",
    "    try:\n",
    "        assert column in df_transactions.columns\n",
    "        print(green_color + f'{column} column is present.' + reset_color)\n",
    "    except:\n",
    "        print(red_color +  f'{column} column is missing from the transactions file' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81865aa6-ad7e-4e35-a55f-4ebb68be8b37",
   "metadata": {},
   "source": [
    "### Dtype check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eb02ac9-b93b-4975-ac5d-53ee925fb619",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_columns_dtype = {'id':'str','sku_id':'str','source_location_id':'str','target_location_id':'str','quantity':'float','type':'str','transaction_date':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e1eb47-8722-4edf-815d-0b9ab0bf8bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mtransaction_date column has dtype mismatch with timestamp\u001b[0m\n",
      "\u001b[92mAll dtypes are matching the requirements\u001b[91m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in transactions_columns_dtype.items():\n",
    "    if dtype == 'timestamp':\n",
    "        try:\n",
    "            pd.to_datetime(df_transactions[column], format='ISO8601', errors='raise')\n",
    "        except:\n",
    "            print(red_color + f\"{column} column has dtype mismatch with {dtype}\" + reset_color)\n",
    "    elif df_transactions[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_transactions[column] = df_transactions[column].astype('str')\n",
    "        except:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    elif df_transactions[column].dtype == 'int' and dtype == 'float':\n",
    "        try:\n",
    "            df_transactions[column] = df_transactions[column].astype('float')\n",
    "        except:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "        \n",
    "print(green_color + 'All dtypes are matching the requirements' + red_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77e327-b32e-4d36-bdd6-ea325401ce66",
   "metadata": {},
   "source": [
    "### Missing values check\n",
    "\n",
    "Checks if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1e711ec-8979-482c-936a-01b122d8dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is populated with data\u001b[0m\n",
      "\u001b[92msku_id column is populated with data\u001b[0m\n",
      "\u001b[92msource_location_id column is populated with data\u001b[0m\n",
      "\u001b[92mtarget_location_id column is populated with data\u001b[0m\n",
      "\u001b[91mThere are null values in the quantity.\u001b[0m\n",
      "\u001b[92mtype column is populated with data\u001b[0m\n",
      "\u001b[92mtransaction_date column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in transactions_columns_dtype:\n",
    "    try:\n",
    "        assert df_transactions[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except: \n",
    "        print(red_color +  f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10157139-c4fe-4265-a461-74942a53667c",
   "metadata": {},
   "source": [
    "### Enum validation\n",
    "\n",
    "Checks if the transactions types are in expected range of values. Expected types: **['in', 'out', 'sale']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f262630-a2c7-4a69-b684-0ca8f1d7b829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mWrong transaction types:\u001b[0m\n",
      "0            IN\n",
      "1            IN\n",
      "2            IN\n",
      "3            IN\n",
      "4            IN\n",
      "           ... \n",
      "1048570    SALE\n",
      "1048571    SALE\n",
      "1048572    SALE\n",
      "1048573    SALE\n",
      "1048574    SALE\n",
      "Name: type, Length: 1048575, dtype: object\n"
     ]
    }
   ],
   "source": [
    "transactions_type_enum = ['in','out','sale']\n",
    "try:\n",
    "    assert df_transactions['type'].isin(transactions_type_enum).all()\n",
    "    print(green_color + 'All transaction types are correct' + reset_color)\n",
    "except:\n",
    "    false_types = df_transactions.loc[~df_transactions['type'].isin(transactions_type_enum), 'type']\n",
    "    print(red_color + 'Wrong transaction types:' + reset_color)\n",
    "    print(false_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c451e-6baa-4bea-80f7-85df3d04bf2b",
   "metadata": {},
   "source": [
    "### Numeric values range check\n",
    "\n",
    "Checks if the values in the column are in expected range. quantity can't be less then 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b70f8457-d3a3-482b-a6e0-5cd024c0a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mquantity contains values less than 0\u001b[0m\n",
      "\u001b[91mPercentage of quantity values less than 0: 1.7239587058627184%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_transactions['quantity'] >= 0).all()\n",
    "    print(green_color + 'All is good, quantity is >= then 0' + reset_color)\n",
    "except:\n",
    "    print(red_color + 'quantity contains values less than 0' + reset_color)\n",
    "    total_count = len(df_transactions['quantity'])\n",
    "    negative_count = (df_transactions['quantity'] < 0).sum()\n",
    "    percentage = (negative_count / total_count) * 100\n",
    "    print(red_color + f\"Percentage of quantity values less than 0: {percentage}%\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe430fa-a78f-45a5-9a26-aebc61e3ea57",
   "metadata": {},
   "source": [
    "# Logical Validation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f109bf24-60de-40a5-91b7-41fead171d4f",
   "metadata": {},
   "source": [
    "## Catalog Logical Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d57a03-52a5-41e9-8b3c-b6cb5ad523d1",
   "metadata": {},
   "source": [
    "### SKU ID is a unique value across all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc491491-d9b3-472e-8671-eb7d436cdd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mDuplicate IDs found in the 'id' column\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert not df_catalog['id'].duplicated().any()\n",
    "    print(green_color + 'No ID duplication found in the Catalog' + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Duplicate IDs found in the 'id' column\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b5a3e-363a-4dd8-bd4c-6b6709777c5f",
   "metadata": {},
   "source": [
    "### For each SKU, at least price or cost should be bigger than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d28742d-8593-4092-af00-d67221ac1343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPrice or Cost is present for each SKU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "invalid_rows = df_catalog[(df_catalog['price'] == 0) & (df_catalog['cost'] == 0)][['id', 'cost', 'price']]\n",
    "total_skus = len(df_catalog)\n",
    "invalid_sku_percentage = len(invalid_rows) / total_skus * 100\n",
    "\n",
    "if len(invalid_rows) > 0:\n",
    "    print(red_color + \"Invalid price or cost values in the following examples:\" + reset_color)\n",
    "    print(invalid_rows.head(5))\n",
    "    print(red_color + f\"Percentage of SKUs with invalid price or cost values: {invalid_sku_percentage:.2f}%\" + reset_color)\n",
    "else:\n",
    "    print(green_color + 'Price or Cost is present for each SKU' + reset_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6141c5-a9b8-4d42-bf07-2a6c6b940702",
   "metadata": {},
   "source": [
    "### All SKUs of a product should have the same categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8a782e4-4616-4191-b11c-1c26b8458c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mColumn 'colors' is not presented.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if 'colors' column is present\n",
    "if 'colors' not in df_catalog.columns:\n",
    "    print(red_color + \"Column 'colors' is not presented.\" + reset_color)\n",
    "else:\n",
    "    # Perform the logical validation\n",
    "    grouped = df_catalog.groupby('product_id')['categories'].nunique()\n",
    "    invalid_ids = grouped[grouped > 1].index\n",
    "\n",
    "    if len(invalid_ids) > 0:\n",
    "        print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "        print(red_color + \"Following products have more than 1 category:\" + reset_color)\n",
    "        print(invalid_ids)\n",
    "    else:\n",
    "        print(green_color + 'All SKUs of a product have same categories' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a993e-20e4-4276-b1ca-a10593339650",
   "metadata": {},
   "source": [
    "### All SKUs of a product should have the same color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1096ea3-45e3-4123-b2e8-eb29b47a6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mColumn 'colors' is not presented.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if 'colors' column is present\n",
    "if 'colors' not in df_catalog.columns:\n",
    "    print(red_color + \"Column 'colors' is not presented.\" + reset_color)\n",
    "else:\n",
    "    # Perform the logical validation\n",
    "    grouped = df_catalog.groupby('product_id')['colors'].nunique()\n",
    "    invalid_ids = grouped[grouped > 1].index\n",
    "\n",
    "    if len(invalid_ids) > 0:\n",
    "        print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "        print(red_color + \"Inconsistent colors for the following first 5 product IDs:\" + reset_color)\n",
    "        print(df_catalog[df_catalog['product_id'].isin(invalid_ids)][['product_id', 'id', 'colors']].head(5))\n",
    "    else:\n",
    "        print(green_color + 'Same color present for all of the SKUs of the same product' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e0882-fdb6-4737-a39b-4972fff816a4",
   "metadata": {},
   "source": [
    "### Number of unique sizes in a product should be equal to the number of SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "351e8021-7c2e-46b5-ba41-6c28f7dd031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mColumn 'size' is not presented.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if 'size' column is present\n",
    "if 'size' not in df_catalog.columns:\n",
    "    print(red_color + \"Column 'size' is not presented.\" + reset_color)\n",
    "else:\n",
    "    # Perform the logical validation\n",
    "    grouped = df_catalog.groupby('product_id')['size'].nunique()\n",
    "    sku_counts = df_catalog.groupby('product_id')['id'].nunique()\n",
    "\n",
    "    invalid_ids = grouped[grouped != sku_counts].index\n",
    "\n",
    "    if len(invalid_ids) > 0:\n",
    "        print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "        print(red_color + \"Mismatch in the number of unique sizes and SKUs for the following product IDs:\" + reset_color)\n",
    "        print(df_catalog[df_catalog['product_id'].isin(invalid_ids)][['id', 'product_id', 'size']])\n",
    "    else:\n",
    "        print(green_color + 'Same size present for all of the SKUs of the same product' + reset_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da59bc-fbef-47d7-a435-18dd9e5d1f78",
   "metadata": {},
   "source": [
    "### At least 1 SKU is not on avoid replenishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bce0f38a-ab32-4874-bdad-5c32801a279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAt least 1 inventory is not on avoid replenishment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_catalog['avoid_replenishment'] == 1).all()\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + 'All inventories are on avoid replenishment' + reset_color)\n",
    "except:\n",
    "    print(green_color + 'At least 1 inventory is not on avoid replenishment' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b512aa3-3bef-4e49-9ad3-f72679dbfd66",
   "metadata": {},
   "source": [
    "## Inventory Logical Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30363304-192f-4e5b-9be6-4bcf61b1e8a6",
   "metadata": {},
   "source": [
    "### At least 1 inventory is not on avoid replenishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "851a401a-f77d-4c7c-920c-99d909b546c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAt least 1 inventory is not on avoid replenishment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_inventory['avoid_replenishment'] == 0).any()\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + 'All inventories are on avoid replenishment' + reset_color)\n",
    "except:\n",
    "    print(green_color + 'At least 1 inventory is not on avoid replenishment' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6599b58-77a4-4dc7-842b-70299b219dcf",
   "metadata": {},
   "source": [
    "### All the Locations exist in the DB or input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d8401f5-5327-4867-ba4b-0186ace55a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid location IDs found in df_inventory\u001b[0m\n",
      "Missing Locations:\n",
      "['000' '001' '002' '003' '004' '005' '006' '007' '008' '009' '010' '011'\n",
      " '012' '013' '014' '016' '017' '018' '019' '020' '021' '022' '023' '025'\n",
      " '026' '027' '028' '029' '033' '034' '035' '036' '037' '038' '039' '040'\n",
      " '041' '042' '043']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert df_inventory['location_id'].isin(df_locations['id']).all()\n",
    "    print(green_color + 'All locations from the Inventory are present in the Locations file' + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Invalid location IDs found in df_inventory\" + reset_color)\n",
    "    print(f\"Missing Locations:\\n{df_inventory.loc[~(df_inventory['location_id'].isin(df_locations['id'])), 'location_id'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4801b-2175-4642-9e98-4a1beb64b795",
   "metadata": {},
   "source": [
    "### All the SKUs exist in the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "735fdd59-9d07-49e6-9d53-5c139397995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid SKU IDs found in df_inventory:\u001b[0m\n",
      "['725887-815' '894081-463' '894331-463' ... 'M00107000024' 'M00112000003'\n",
      " 'YFM19CPT']\n",
      "\u001b[91mTotal SKUs: 33468\u001b[0m\n",
      "\u001b[91mNumber of invalid SKUs: 3733\u001b[0m\n",
      "\u001b[91mPercentage of invalid SKUs from total SKUs: 11.15%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "invalid_sku_ids = df_inventory[~df_inventory['sku_id'].isin(df_catalog['id'])]['sku_id'].unique()\n",
    "\n",
    "if invalid_sku_ids.any():\n",
    "    print(red_color + \"Invalid SKU IDs found in df_inventory:\" + reset_color)\n",
    "    print(invalid_sku_ids)\n",
    "\n",
    "    invalid_sku_count = len(invalid_sku_ids)\n",
    "    total_sku_count = len(df_inventory['sku_id'].unique())\n",
    "\n",
    "    print(red_color + 'Total SKUs: {}'.format(total_sku_count) + reset_color)\n",
    "    print(red_color + 'Number of invalid SKUs: {}'.format(invalid_sku_count) + reset_color)\n",
    "\n",
    "    invalid_sku_percentage = (invalid_sku_count / total_sku_count) * 100\n",
    "    print(red_color + 'Percentage of invalid SKUs from total SKUs: {:.2f}%'.format(invalid_sku_percentage) + reset_color)\n",
    "\n",
    "else:\n",
    "    print(green_color + \"All SKU IDs in df_inventory exist in the df_catalog\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5c181-9577-4800-82bf-f11587df5dfb",
   "metadata": {},
   "source": [
    "## Locations Logical Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3396cd7-86b2-462c-98cc-247161ccfecc",
   "metadata": {},
   "source": [
    "### Location ID is a unique value across all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "397b7ae3-c4a7-483e-83f1-828b82ba0876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mNo ID duplication found in the Locations file\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert not df_locations['id'].duplicated().any()\n",
    "    print(green_color + 'No ID duplication found in the Locations file' + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Duplicate IDs found in the 'id' column\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea6665-e08f-4dd5-bb90-61d6a44fd38b",
   "metadata": {},
   "source": [
    "### There is at least 1 location from type “store”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9efc87ca-55d2-4039-802b-c8eb4dbd0ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNo locations of type 'store' found\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_locations['type'] == 'store').any()\n",
    "    print(green_color + \"At least one location of type 'store' exists\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"No locations of type 'store' found\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ce2c6-206e-4e08-aa74-dabd12d994b1",
   "metadata": {},
   "source": [
    "### There is at least 1 location from type “warehouse”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2925a389-cbe3-406d-af1b-7b783d576bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNo locations of type 'warehouse' found\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_locations['type'] == 'warehouse').any()\n",
    "    print(green_color + \"At least one location of type 'warehouse' exists\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"No locations of type 'warehouse' found\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd8e98-1797-4543-9466-e16cb3e60bad",
   "metadata": {},
   "source": [
    "### All the location types are from the optional values list (wh/store/plant/supplier/client/unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31799c69-dae7-4239-832e-d951c5bbf2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid location types found:\u001b[0m\n",
      "{'Warehouse', 'Shop', 'Warehouse '}\n"
     ]
    }
   ],
   "source": [
    "optional_values = {'warehouse', 'store', 'plant', 'supplier', 'client', 'unknown','outlet','ecommerce'}\n",
    "location_types = set(df_locations['type'].unique())\n",
    "invalid_types = location_types - optional_values\n",
    "\n",
    "try:\n",
    "    assert location_types.issubset(optional_values)\n",
    "    print(green_color + \"All location types are from the optional values list\" + reset_color)\n",
    "except:\n",
    "    if invalid_types:\n",
    "        print(red_color + \"Invalid location types found:\" + reset_color)\n",
    "        print(invalid_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934a5f7-1eba-4e96-8c72-eaf57c68a6bb",
   "metadata": {},
   "source": [
    "### At least 1 location is not on avoid replenishment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7b654d0-c68d-4b2a-b9d5-823486217234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNon mandatory column validation\u001b[0m\n",
      "\u001b[91mAll locations are on avoid replenishment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_locations['avoid_replenishment'] == 0).any()\n",
    "    print(green_color + 'At least 1 location is not on avoid replenishment' + reset_color)\n",
    "except: \n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + 'All locations are on avoid replenishment' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88d24a-c53d-40ac-81fe-0015bba88618",
   "metadata": {},
   "source": [
    "## Transactions Logical Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb2031-72ab-44a2-8f55-59b69778d8f2",
   "metadata": {},
   "source": [
    "### Transaction ID is a unique value across all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5208a10-823e-4444-ac0c-cbfc394dc89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTransaction ID is unique across all rows\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert not df_transactions['id'].duplicated().any()\n",
    "    print(green_color + \"Transaction ID is unique across all rows\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Transaction ID is not unique\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b91ee4-ce2a-40df-9869-3fbe1936eca1",
   "metadata": {},
   "source": [
    "### Source location is different from the target location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a26dd065-6010-460c-9f1f-894728dc3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSource location is different from the target location in all rows\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_transactions['source_location_id'].ne(df_transactions['target_location_id'])).all()\n",
    "    print(green_color + \"Source location is different from the target location in all rows\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Source location is the same as the target location\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b965d-b099-4d58-bb1f-c4e122da8396",
   "metadata": {},
   "source": [
    "### Source location OR Target location exist as a known location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43e6e535-cc4a-4821-95a7-23454f74a335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid source locations:\u001b[0m\n",
      "81802     34\n",
      "81803     34\n",
      "81804     34\n",
      "81805     34\n",
      "81806     34\n",
      "          ..\n",
      "442329     0\n",
      "442330     0\n",
      "442331     0\n",
      "450402     0\n",
      "450403     0\n",
      "Name: source_location_id, Length: 292, dtype: object\n",
      "\u001b[91mInvalid target locations:\u001b[0m\n",
      "81802      82303\n",
      "81803      82304\n",
      "81804      82305\n",
      "81805      82306\n",
      "81806      82307\n",
      "           ...  \n",
      "442329    442830\n",
      "442330    442831\n",
      "442331    442832\n",
      "450402    450903\n",
      "450403    450904\n",
      "Name: target_location_id, Length: 292, dtype: object\n"
     ]
    }
   ],
   "source": [
    "known_location_ids = set(df_locations['id'].unique())\n",
    "invalid_locations = ~(df_transactions['source_location_id'].isin(known_location_ids) |\n",
    "                     df_transactions['target_location_id'].isin(known_location_ids))\n",
    "\n",
    "invalid_source_locations = df_transactions.loc[invalid_locations, 'source_location_id']\n",
    "invalid_target_locations = df_transactions.loc[invalid_locations, 'target_location_id']\n",
    "\n",
    "if invalid_locations.any():\n",
    "    if invalid_source_locations.any():\n",
    "        print(red_color + \"Invalid source locations:\" + reset_color)\n",
    "        print(invalid_source_locations)\n",
    "    if invalid_target_locations.any():\n",
    "        print(red_color + \"Invalid target locations:\" + reset_color)\n",
    "        print(invalid_target_locations)\n",
    "else:\n",
    "    print(green_color + \"All source and target locations exist as known locations\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1175a2b-1d89-473b-91cf-52a64df4e6df",
   "metadata": {},
   "source": [
    "### All SKU_ids exist in the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cea9798e-7810-4c75-aa0a-9242edc2fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid SKU IDs found in transactions:\u001b[0m\n",
      "['88850000' 'FU22-10000' 'FU22J-10000' ... '5052-01-0001' '22RMHA0009'\n",
      " 'LIV10363']\n",
      "\u001b[91mTotal SKUs: 22062\u001b[0m\n",
      "\u001b[91mNumber of invalid SKUs: 2153\u001b[0m\n",
      "\u001b[91mPercentage of invalid SKUs from total SKUs: 9.76%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "invalid_sku_ids = df_transactions[~df_transactions['sku_id'].isin(df_catalog['id'])]['sku_id'].unique()\n",
    "\n",
    "if invalid_sku_ids.any():\n",
    "    print(red_color + \"Invalid SKU IDs found in transactions:\" + reset_color)\n",
    "    print(invalid_sku_ids)\n",
    "\n",
    "    invalid_sku_count = len(invalid_sku_ids)\n",
    "    total_sku_count = len(df_transactions['sku_id'].unique())\n",
    "\n",
    "    print(red_color + 'Total SKUs: {}'.format(total_sku_count) + reset_color)\n",
    "    print(red_color + 'Number of invalid SKUs: {}'.format(invalid_sku_count) + reset_color)\n",
    "\n",
    "    invalid_sku_percentage = (invalid_sku_count / total_sku_count) * 100\n",
    "    print(red_color + 'Percentage of invalid SKUs from total SKUs: {:.2f}%'.format(invalid_sku_percentage) + reset_color)\n",
    "\n",
    "else:\n",
    "    print(green_color + \"All SKU IDs in transactions exist in the df_catalog\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3fc31-1875-4ff8-8ceb-899a1accc758",
   "metadata": {},
   "source": [
    "### SKU_id exist in the Source location OR Target location\n",
    "\n",
    "Check if the SKU_id - target_location_id or SKU_id - source_location_id combinations exists in the df_inventory, if both of them are missing - raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da995516-f936-45bf-af9b-dc7a4ae36ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mSKUs for which both SKU_id - target_location_id and SKU_id - source_location_id don't exist in df_inventory:\u001b[0m\n",
      "            sku_id source_location_id target_location_id\n",
      "0              UR1                501                  1\n",
      "1              UR1                502                  4\n",
      "2              UR1                503                  6\n",
      "3              UR1                504                  7\n",
      "4              UR1                505                  8\n",
      "...            ...                ...                ...\n",
      "1043555  921519KSH            1049071                  9\n",
      "1043556  921519KSH            1049072                  9\n",
      "1043557  921519KSH            1049073                  9\n",
      "1043558  921519KSH            1049074                  9\n",
      "1043559  921519KSH            1049075                  9\n",
      "\n",
      "[1043560 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "inventory_sku_location_combinations = set(zip(df_inventory['sku_id'], df_inventory['location_id']))\n",
    "\n",
    "missing_combinations = []\n",
    "\n",
    "for _, row in df_transactions.iterrows():\n",
    "    sku = row['sku_id']\n",
    "    target_location = row['target_location_id']\n",
    "    source_location = row['source_location_id']\n",
    "    \n",
    "    if (sku, target_location) not in inventory_sku_location_combinations and (sku, source_location) not in inventory_sku_location_combinations:\n",
    "        missing_combinations.append((sku, target_location, source_location))\n",
    "\n",
    "if len(missing_combinations) > 0:\n",
    "    missing_df = pd.DataFrame(missing_combinations, columns=['sku_id', 'source_location_id', 'target_location_id'])\n",
    "    print(red_color + \"SKUs for which both SKU_id - target_location_id and SKU_id - source_location_id don't exist in df_inventory:\" + reset_color)\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(green_color + \"All SKUs have either SKU_id - target_location_id or SKU_id - source_location_id combinations in df_inventory\" + reset_color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
