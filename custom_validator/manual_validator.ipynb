{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04616de-4467-4fca-a3eb-44b6d3794449",
   "metadata": {},
   "source": [
    "# Cloud Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c364588",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15e6841-2e73-4f6f-9908-fa9636bb7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_color = '\\033[91m'\n",
    "green_color = '\\033[92m'\n",
    "reset_color = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a880e-2607-443a-8a98-d00632cd5396",
   "metadata": {},
   "source": [
    "# Data Upload\n",
    "In the data folder should exists 4 files:\n",
    "1. catalog - file that contains all information about the SKU\n",
    "2. inventory - file that contains current inventory status of SL-SKU\n",
    "3. location - file that contains all information about the location\n",
    "4. transactions - file that contains all information about all transactions (Sl-SKU based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3111edbe-057d-4a95-93e5-33fabcc35762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of the input files\n",
    "catalog_file_name = 'catalog.csv'\n",
    "inventory_file_name = 'inventory.csv'\n",
    "locations_file_name = 'locations.csv'\n",
    "transactions_file_name = 'transactions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335fa6f0-f875-4303-a3f0-c440d234f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_file_name\n",
    "\n",
    "df_catalog = pd.read_csv(catalog_file_name,\n",
    "                        dtype={\n",
<<<<<<< HEAD:research/cloud/validator/cloud_validator_template.ipynb
    "                                'id': 'str'\n",
=======
    "                                'id': 'str',\n",
    "                                'name': 'str', \n",
    "                                'product_id': 'str'\n",
>>>>>>> b6ebbaeda4c5be00605251e03239c845436ed19f:images/onebeat-validator/common/manual_validator.ipynb
    "                             })\n",
    "df_inventory = pd.read_csv(inventory_file_name, \n",
    "                            dtype={\n",
    "                                'location_id': 'str', \n",
    "                                'sku_id': 'str',\n",
    "                                'source_location_id':'str'\n",
    "                             })\n",
    "df_locations = pd.read_csv(locations_file_name, \n",
    "                            dtype={\n",
    "                                'id': 'str',\n",
    "                                'name': 'str',\n",
    "                                'type': 'str'\n",
    "                             })\n",
    "df_transactions = pd.read_csv(transactions_file_name, \n",
    "                               dtype={\n",
    "                                   'location_id': 'str', \n",
    "                                   'sku_id': 'str',\n",
    "                                   'source_location_id':'str',\n",
    "                                   'target_location_id': 'str'\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee487c0a-e073-476b-92f4-390344a47f9d",
   "metadata": {},
   "source": [
    "# Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e9681-ae21-4e94-8680-06460b9139aa",
   "metadata": {},
   "source": [
    "## Mandatory Columns\n",
    "Checking that all the mandator columns are present, columns - [id,name,product_id,price,cost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca89a22d-05d1-474e-850c-c9bcb94975ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_column_list = ['id','name','product_id','price','cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c2e0d6-d1e6-4f61-94de-e0f69ff8f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll columns are present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in catalog_column_list:\n",
    "    assert column in df_catalog.columns, f'{column} column is missing from the catalog file' \n",
    "print(green_color + 'All columns are present.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991b783-45a7-4e1f-baba-203a1a37b7bd",
   "metadata": {},
   "source": [
    "### Dtype check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21c2978-a0bc-436d-bd14-fddaae9456c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Dtypes of mandator columns\n",
    "catalog_columns_dtype = {'id':'str','name':'str','product_id':'str','price':'float','cost':'float'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64df82d9-1b80-4e22-9307-eedcb924e41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalog['id'].dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3446f27-23c0-4e1b-bd24-16e374319931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mid column has dtype mismatch with str\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in catalog_columns_dtype.items():\n",
    "    if df_catalog[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_catalog[column] = df_catalog[column].astype('str')\n",
    "        except ValueError:\n",
    "            raise ValueError(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    else:\n",
    "        try:\n",
    "            pd.to_numeric(df_catalog[column], errors='raise', downcast=dtype)\n",
    "        except (TypeError, ValueError):\n",
    "            print(red_color + f\"{column} column has dtype mismatch with {dtype}\" + reset_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182de1a-ffdd-48ab-8624-be6e953cc541",
   "metadata": {},
   "source": [
    "### Missing values check\n",
    "\n",
    "Checks if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a7b39f-e1b6-49dd-88c1-d1efefa061b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is populated with data\u001b[0m\n",
      "\u001b[92mname column is populated with data\u001b[0m\n",
      "\u001b[92mproduct_id column is populated with data\u001b[0m\n",
      "\u001b[92mprice column is populated with data\u001b[0m\n",
      "\u001b[92mcost column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in catalog_column_list:\n",
    "    try:\n",
    "        assert df_catalog[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b74e1-9cbc-4025-8120-797ffb334a80",
   "metadata": {},
   "source": [
    "### Numeric values range check\n",
    "\n",
    "Checks if the values in the column are in expected range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a132fc5-f2ca-4731-993a-f9aad413ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll is good, Price is >= 0\u001b[0m\n",
      "\u001b[92mAll is good, delimiters in the Price column are in expected range\u001b[91m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_catalog['price'] >= 0).all()\n",
    "    print(green_color + 'All is good, Price is >= 0' + reset_color)\n",
    "except AssertionError:\n",
    "    print(red_color + 'Price contains values less than 0' + reset_color)\n",
    "    total_count = len(df_catalog['price'])\n",
    "    negative_count = (df_catalog['price'] < 0).sum()\n",
    "    percentage = (negative_count / total_count) * 100\n",
    "    print(red_color + f\"Percentage of price values less than 0: {percentage}%\" + reset_color)\n",
    "\n",
    "try:\n",
    "    assert np.issubdtype(df_catalog['price'].dtype, np.floating) or np.issubdtype(df_catalog['price'].dtype, np.integer)\n",
    "    print(green_color + 'All is good, delimiters in the Price column are in expected range' + red_color)\n",
    "except:\n",
    "    print(red_color + 'The Price column contains non-numeric values' + reset_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1045a5-6ee1-4247-9d8d-fa022c5e4aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll is good, Cost is >= then 0\u001b[0m\n",
      "\u001b[92mAll is good, delimiters in the Cost column are in expected range\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_catalog['cost'] >= 0).all()\n",
    "    print(green_color + 'All is good, Cost is >= then 0' + reset_color)\n",
    "except:\n",
    "    print(red_color + 'Cost contains values less than 0' + reset_color)\n",
    "    total_count = len(df_catalog['cost'])\n",
    "    negative_count = (df_catalog['cost'] < 0).sum()\n",
    "    percentage = (negative_count / total_count) * 100\n",
    "    print(red_color + f\"Percentage of cost values less than 0: {percentage}%\" + reset_color)\n",
    "\n",
    "try:\n",
    "    assert np.issubdtype(df_catalog['cost'].dtype, np.floating) or np.issubdtype(df_catalog['cost'].dtype, np.integer)\n",
    "    print(green_color + 'All is good, delimiters in the Cost column are in expected range' + reset_color)\n",
    "except:\n",
    "    print(red_color + 'The Cost column contains non-numeric values' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c23f8-4c1e-477d-a358-063ae12e2f21",
   "metadata": {},
   "source": [
    "# Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7ffdf-a016-477f-95a6-1921e574ef21",
   "metadata": {},
   "source": [
    "## Mandatory Columns\n",
    "Checking that all the mandator columns are present, columns - [location_id,sku_id,source_location_id,transit_qty,site_qty,status_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b38a99a-4efc-4de8-ab6b-20f7e645dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns list\n",
    "inventory_column_list = ['location_id','sku_id','source_location_id','transit_qty','site_qty','status_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c03e028-89f0-4e03-8381-dfa4572d0089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mlocation_id column is present.\u001b[0m\n",
      "\u001b[92msku_id column is present.\u001b[0m\n",
      "\u001b[92msource_location_id column is present.\u001b[0m\n",
      "\u001b[92mtransit_qty column is present.\u001b[0m\n",
      "\u001b[92msite_qty column is present.\u001b[0m\n",
      "\u001b[92mstatus_date column is present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in inventory_column_list:\n",
    "    try:\n",
    "        assert column in df_inventory.columns\n",
    "        print(green_color + f'{column} column is present.' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'{column} column is missing from the inventory file'  + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6d45d-66fb-4088-b053-a7958bc472fe",
   "metadata": {},
   "source": [
    "### Dtype check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264330a9-4042-4bdf-99a0-3dfa8359347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Dtypes of mandator columns\n",
    "inventory_columns_dtype = {'location_id':'str',\n",
    "                           'sku_id':'str',\n",
    "                           'source_location_id':'uuid',\n",
    "                           'transit_qty':'float',\n",
    "                           'site_qty':'float',\n",
    "                           'status_date':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995e02ea-b7c7-4c15-a0ba-2a579c7949b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mEach status_date, sku_id, and location_id has only one unique source_location_id.\u001b[0m\n",
      "\u001b[92mAll dtypes are matching the requirements\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in inventory_columns_dtype.items():\n",
    "    if dtype == 'timestamp':\n",
    "        try:\n",
    "            pd.to_datetime(df_inventory[column], format='ISO8601', errors='raise')\n",
    "        except (TypeError, ValueError):\n",
    "            print(red_color + f\"{column} column has dtype mismatch with {dtype}\" + reset_color)\n",
    "    elif df_inventory[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_inventory[column] = df_inventory[column].astype('str')\n",
    "        except ValueError:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    elif df_inventory[column].dtype == 'int' and dtype == 'float':\n",
    "        try:\n",
    "            df_inventory[column] = df_inventory[column].astype('float')\n",
    "        except ValueError:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    elif dtype == 'uuid':\n",
    "        grouped = df_inventory.groupby(['status_date', 'sku_id', 'location_id'])['source_location_id'].nunique()\n",
    "        if (grouped > 1).any():\n",
    "            print(red_color + \"Multiple unique source_location_id found for the same status_date, sku_id, and location_id.\" + reset_color)\n",
    "        else:\n",
    "            print(green_color + \"Each status_date, sku_id, and location_id has only one unique source_location_id.\" + reset_color)\n",
    "        \n",
    "print(green_color + 'All dtypes are matching the requirements' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84a79b-ac1a-4459-8072-075601dfc03d",
   "metadata": {},
   "source": [
    "### Missing values check\n",
    "\n",
    "Checks if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44034305-2a97-44a0-ad5f-abc2d5d3668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mlocation_id column is populated with data\u001b[0m\n",
      "\u001b[92msku_id column is populated with data\u001b[0m\n",
      "\u001b[92msource_location_id column is populated with data\u001b[0m\n",
      "\u001b[92mtransit_qty column is populated with data\u001b[0m\n",
      "\u001b[92msite_qty column is populated with data\u001b[0m\n",
      "\u001b[92mstatus_date column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in inventory_column_list:\n",
    "    try:\n",
    "        assert df_inventory[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9604737d-3e41-43c9-b390-b32518e39be7",
   "metadata": {},
   "source": [
    "### Numeric values range check\n",
    "\n",
    "Checks if the values in the co\n",
    "lumn are in expected range.\n",
    "transit_qty and site_qty can be less then 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a73a673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mThere is negative transit_qty for some inventories\u001b[0m\n",
      "      location_id  sku_id source_location_id  transit_qty  site_qty   \n",
      "65            188   54168                188         -1.0       0.0  \\\n",
      "6234          198  158869                198         -1.0       0.0   \n",
      "12041         102  185482                102         -1.0       0.0   \n",
      "15506         079  199224                079         -1.0       0.0   \n",
      "18259         005  202193                005         -1.0       0.0   \n",
      "18910         004  203573                004         -1.0       0.0   \n",
      "\n",
      "       reserved_qty  min_stock  max_stock  replenishment_lead_time   \n",
      "65              0.0          1          1                      NaN  \\\n",
      "6234            0.0          1          1                      NaN   \n",
      "12041           0.0          1          1                      NaN   \n",
      "15506           0.0          1          1                      NaN   \n",
      "18259           0.0          1          1                      NaN   \n",
      "18910           0.0          1          1                      NaN   \n",
      "\n",
      "      status_date  avoid_replenishment  \n",
      "65     2023-08-10                    0  \n",
      "6234   2023-08-10                    0  \n",
      "12041  2023-08-10                    0  \n",
      "15506  2023-08-10                    0  \n",
      "18259  2023-08-10                    0  \n",
      "18910  2023-08-10                    0  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert df_inventory['transit_qty'].min() >= 0\n",
    "    print(green_color + f'There is no negative transit_qty' + reset_color)\n",
    "except:\n",
    "    print(red_color + f'There is negative transit_qty for some inventories' + reset_color)\n",
    "    print(df_inventory[df_inventory['transit_qty']<0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec838087-5d25-401d-84b0-5f1a63d15233",
   "metadata": {},
   "source": [
    "# Locations\n",
    "Checking that all the mandator columns are present, columns - [id,name,type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d02f8528-b09f-4c6b-992e-715eb96abfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_column_list = ['id','name','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b89c45ba-f217-460d-ad04-2a3d358989e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is present.\u001b[0m\n",
      "\u001b[92mname column is present.\u001b[0m\n",
      "\u001b[92mtype column is present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in locations_column_list:\n",
    "    try:\n",
    "        assert column in df_locations.columns\n",
    "        print(green_color + f'{column} column is present.' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'{column} column is missing from the locations file' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef682b8a-e29a-4186-9680-baafcb4fa62c",
   "metadata": {},
   "source": [
    "### Dtype check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7addde55-1d0a-4321-85e3-15fa823f2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Dtypes of mandator columns\n",
    "locations_columns_dtype = {'id':'str',\n",
    "                           'name':'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a4995f-9f16-490e-86ae-772aac8ead8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column dtype is matching the requirements\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in locations_columns_dtype.items():\n",
    "    if df_locations[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_locations[column] = df_locations[column].astype('str')\n",
    "            print(green_color + f'{column} column dtype is matching the requirements' + reset_color)\n",
    "        except ValueError:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39d391-6140-4139-978a-2f810de403d4",
   "metadata": {},
   "source": [
    "### Missing values check\n",
    "Checks if the column contains any null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20fe6a14-3bf9-4867-8a5c-cfefb9bd4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is populated with data\u001b[0m\n",
      "\u001b[92mname column is populated with data\u001b[0m\n",
      "\u001b[92mtype column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in locations_column_list:\n",
    "    try:\n",
    "        assert df_locations[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except:\n",
    "        print(red_color + f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b903d-b547-4e10-9628-5b143bafe1c3",
   "metadata": {},
   "source": [
    "### Enum validation\n",
    "\n",
    "Checks if the location types are in expected range of values.\n",
    "Expected types: ['store', 'warehouse', 'vwarehouse','ecommerce', 'plant', 'supplier','outlet', 'unknown', 'client']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "879f6b08-3e89-49b8-a570-9e615ac80ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll location types are correct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "locations_type_enum = ['store', 'warehouse', 'vwarehouse','ecommerce', 'plant', 'supplier','outlet', 'unknown', 'client']\n",
    "try:\n",
    "    assert df_locations['type'].isin(locations_type_enum).all()\n",
    "    print(green_color + 'All location types are correct' + reset_color)\n",
    "except:\n",
    "    print(red_color + f\"Wrong location type in column: {column}\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd3967-8046-4a99-bb95-ca664678d38f",
   "metadata": {},
   "source": [
    "# Transactions\n",
    "Checking that all the mandator columns are present, columns - ['id','sku_id','source_location_id','target_location_id','quantity','type','transaction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b930479f-87e6-4fbb-9682-f81532bd09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_column_list = ['id','sku_id','source_location_id','target_location_id','quantity',\n",
    "                            'type','transaction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a60fbb96-2ca1-44b0-90ea-331fbcb38d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is present.\u001b[0m\n",
      "\u001b[92msku_id column is present.\u001b[0m\n",
      "\u001b[92msource_location_id column is present.\u001b[0m\n",
      "\u001b[92mtarget_location_id column is present.\u001b[0m\n",
      "\u001b[92mquantity column is present.\u001b[0m\n",
      "\u001b[92mtype column is present.\u001b[0m\n",
      "\u001b[92mtransaction_date column is present.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in transactions_column_list:\n",
    "    try:\n",
    "        assert column in df_transactions.columns\n",
    "        print(green_color + f'{column} column is present.' + reset_color)\n",
    "    except:\n",
    "        print(red_color +  f'{column} column is missing from the transactions file' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42665728-e94f-4eea-aa7d-f04ac11bb046",
   "metadata": {},
   "source": [
    "### Dtype check\n",
    "\n",
    "Chacks if the column can be transformed in to the data type that the sustem expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf910f5-7476-4dea-a25b-be9fb4055ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_columns_dtype = {'id':'str','sku_id':'str','source_location_id':'str','target_location_id':'str','quantity':'float','type':'str','transaction_date':'timestamp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "603abef1-2a79-45f3-a3d9-4d20527aef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll dtypes are matching the requirements\u001b[91m\n"
     ]
    }
   ],
   "source": [
    "for column, dtype in transactions_columns_dtype.items():\n",
    "    if dtype == 'timestamp':\n",
    "        try:\n",
    "            pd.to_datetime(df_transactions[column], format='ISO8601', errors='raise')\n",
    "        except:\n",
    "            print(red_color + f\"{column} column has dtype mismatch with {dtype}\" + reset_color)\n",
    "    elif df_transactions[column].dtype == 'object' and dtype == 'str':\n",
    "        try:\n",
    "            df_transactions[column] = df_transactions[column].astype('str')\n",
    "        except:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "    elif df_transactions[column].dtype == 'int' and dtype == 'float':\n",
    "        try:\n",
    "            df_transactions[column] = df_transactions[column].astype('float')\n",
    "        except:\n",
    "            print(red_color + f\"Unable to change dtype of {column} column from object to str\" + reset_color)\n",
    "        \n",
    "print(green_color + 'All dtypes are matching the requirements' + red_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe8f44-e418-4033-8c82-6ac342c4c8e7",
   "metadata": {},
   "source": [
    "### Missing values check\n",
    "Checks if the column contains any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "560d27bc-812c-47d9-852d-d9b5e442f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mid column is populated with data\u001b[0m\n",
      "\u001b[92msku_id column is populated with data\u001b[0m\n",
      "\u001b[92msource_location_id column is populated with data\u001b[0m\n",
      "\u001b[92mtarget_location_id column is populated with data\u001b[0m\n",
      "\u001b[92mquantity column is populated with data\u001b[0m\n",
      "\u001b[92mtype column is populated with data\u001b[0m\n",
      "\u001b[92mtransaction_date column is populated with data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for column in transactions_columns_dtype:\n",
    "    try:\n",
    "        assert df_transactions[column].isnull().sum().sum() == 0\n",
    "        print(green_color + f'{column} column is populated with data' + reset_color)\n",
    "    except: \n",
    "        print(red_color +  f'There are null values in the {column}.' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c43e13-5466-4449-8908-3447de56e0f7",
   "metadata": {},
   "source": [
    "### Enum validation\n",
    "Checks if the transactions\n",
    "types are in expected range of values.\n",
    "Expected types: ['in', 'out', 'sale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47f9489d-b8ac-434b-8eee-04cbe0a16088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll transaction types are correct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transactions_type_enum = ['in','out','sale']\n",
    "try:\n",
    "    assert df_transactions['type'].isin(transactions_type_enum).all()\n",
    "    print(green_color + 'All transaction types are correct' + reset_color)\n",
    "except:\n",
    "    false_types = df_transactions.loc[~df_transactions['type'].isin(transactions_type_enum), 'type']\n",
    "    print(red_color + 'Wrong transaction types:' + reset_color)\n",
    "    print(false_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee481293-04aa-4cb7-a659-1a2fd70ae34f",
   "metadata": {},
   "source": [
    "### Numeric values range check\n",
    "Checks if the values in the column are in expected range.\n",
    "quantity can't be less then 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75b33983-651b-4d36-8481-4e0fd03d466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll is good, quantity is >= then 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_transactions['quantity'] >= 0).all()\n",
    "    print(green_color + 'All is good, quantity is >= then 0' + reset_color)\n",
    "except:\n",
    "    print(red_color + 'quantity contains values less than 0' + reset_color)\n",
    "    total_count = len(df_transactions['quantity'])\n",
    "    negative_count = (df_transactions['quantity'] < 0).sum()\n",
    "    percentage = (negative_count / total_count) * 100\n",
    "    print(red_color + f\"Percentage of quantity values less than 0: {percentage}%\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218a7b1-30c3-4556-884c-76be9d29c86d",
   "metadata": {},
   "source": [
    "# Logical Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee304d-a091-4d1e-8d5e-33e7d16f71e3",
   "metadata": {},
   "source": [
    "## Catalog Logical Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71864b-94d1-40d2-b125-0f0627dc3e7d",
   "metadata": {},
   "source": [
    "##### **SKU ID is a unique value across all rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af518d84-7c70-47b9-88e0-9636ba8e547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mNo ID duplication found in the Catalog\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert not df_catalog['id'].duplicated().any()\n",
    "    print(green_color + 'No ID duplication found in the Catalog' + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Duplicate IDs found in the 'id' column\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275b264-0633-4412-abf9-e72e2c13fae3",
   "metadata": {},
   "source": [
    "##### **For each SKU, at least price or cost should be bigger than 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89f6a1b3-745a-430d-b985-4e96610ee089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPrice or Cost is present for each SKU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "invalid_rows = df_catalog[(df_catalog['price'] == 0) & (df_catalog['cost'] == 0)][['id', 'cost', 'price']]\n",
    "total_skus = len(df_catalog)\n",
    "invalid_sku_percentage = len(invalid_rows) / total_skus * 100\n",
    "\n",
    "if len(invalid_rows) > 0:\n",
    "    print(red_color + \"Invalid price or cost values in the following examples:\" + reset_color)\n",
    "    print(invalid_rows.head(5))\n",
    "    print(red_color + f\"Percentage of SKUs with invalid price or cost values: {invalid_sku_percentage:.2f}%\" + reset_color)\n",
    "else:\n",
    "    print(green_color + 'Price or Cost is present for each SKU' + reset_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f0f4c-9c02-4c1c-a638-20bfe56fc996",
   "metadata": {},
   "source": [
    "##### **All SKUs of a product should have the same categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d518f78-3ed6-433c-9c0b-e04b848f7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll SKUs of a product have same categories\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grouped = df_catalog.groupby('product_id')['categories'].nunique()\n",
    "invalid_ids = grouped[grouped > 1].index\n",
    "\n",
    "if len(invalid_ids) > 0:\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + \"Following products have more than 1 category:\" + reset_color)\n",
    "    print(invalid_ids)\n",
    "else:\n",
    "    print(green_color + 'All SKUs of a product have same categories' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5d577-41b8-4064-9b3c-c55c7e55bec3",
   "metadata": {},
   "source": [
    "##### **All SKUs of a product should have the same color**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b43a83b5-da89-4572-8af2-c84c8428ce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSame color present for all of the SKUs of the same product\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grouped = df_catalog.groupby('product_id')['colors'].nunique()\n",
    "invalid_ids = grouped[grouped > 1].index\n",
    "\n",
    "if len(invalid_ids) > 0:\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + \"Inconsistent colors for the following first 5 product IDs:\" + reset_color)\n",
    "    print(df_catalog[df_catalog['product_id'].isin(invalid_ids)][['product_id', 'id', 'colors']].head(5))\n",
    "else:\n",
    "    print(green_color + 'Same color present for all of the SKUs of the same product' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f154a6-2a4d-444d-bf37-4ad15bf8d474",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Number of unique sizes in a product should be equal to the number of SKUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1d36e61-b969-4f1f-8125-71da5459ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSame size present for all of the SKUs of the same product\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grouped = df_catalog.groupby('product_id')['size'].nunique()\n",
    "sku_counts = df_catalog.groupby('product_id')['id'].nunique()\n",
    "\n",
    "invalid_ids = grouped[grouped != sku_counts].index\n",
    "\n",
    "if len(invalid_ids) > 0:\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + \"Mismatch in the number of unique sizes and SKUs for the following product IDs:\" + reset_color)\n",
    "    print(df_catalog[df_catalog['product_id'].isin(invalid_ids)][['id', 'product_id', 'size']])\n",
    "else:\n",
    "    print(green_color + 'Same size present for all of the SKUs of the same product' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c5858b-e4c3-442c-a658-a5b2d6a49ee1",
   "metadata": {},
   "source": [
    "##### **At least 1 SKU is not on avoid replenishment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19023b25-97a8-4019-b853-caefd4eab777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAt least 1 inventory is not on avoid replenishment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_catalog['avoid_replenishment'] == 1).all()\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + 'All inventories are on avoid replenishment' + reset_color)\n",
    "except:\n",
    "    print(green_color + 'At least 1 inventory is not on avoid replenishment' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c2699-233e-4505-8b22-27b00a9682de",
   "metadata": {},
   "source": [
    "## Inventory Logical Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021a51d-aca6-4a20-8b45-7a00a761bdaf",
   "metadata": {},
   "source": [
    "##### **At least 1 inventory is not on avoid replenishment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ff1227b-718f-4802-a167-c64d4174f8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNon mandatory column validation\u001b[0m\n",
      "\u001b[91mAll inventories are on avoid replenishment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_inventory['avoid_replenishment'] == 0).any()\n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + 'All inventories are on avoid replenishment' + reset_color)\n",
    "except:\n",
    "    print(green_color + 'At least 1 inventory is not on avoid replenishment' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d23b13-74e2-435e-958d-efab19d9cd91",
   "metadata": {},
   "source": [
    "##### **All the Locations exist in the DB or input files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22376c3b-89b5-4d1b-90d5-574dc1ab3b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid location IDs found in df_inventory\u001b[0m\n",
      "Missing Locations:\n",
      "['290']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert df_inventory['location_id'].isin(df_locations['id']).all()\n",
    "    print(green_color + 'All locations from the Inventory are present in the Locations file' + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Invalid location IDs found in df_inventory\" + reset_color)\n",
    "    print(f\"Missing Locations:\\n{df_inventory.loc[~(df_inventory['location_id'].isin(df_locations['id'])), 'location_id'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f66717-68c3-4f46-b838-5c8cc289f0b2",
   "metadata": {},
   "source": [
    "##### **All the SKUs exist in the Catalog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54f14169-612a-4ec9-abd0-0e9b9984fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid SKU IDs found in df_inventory:\u001b[0m\n",
      "['39961' '39969' '51916' ... '222785' '222786' '222788']\n",
      "\u001b[91mTotal SKUs: 7486\u001b[0m\n",
      "\u001b[91mNumber of invalid SKUs: 7486\u001b[0m\n",
      "\u001b[91mPercentage of invalid SKUs from total SKUs: 100.00%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "invalid_sku_ids = df_inventory[~df_inventory['sku_id'].isin(df_catalog['id'])]['sku_id'].unique()\n",
    "\n",
    "if invalid_sku_ids.any():\n",
    "    print(red_color + \"Invalid SKU IDs found in df_inventory:\" + reset_color)\n",
    "    print(invalid_sku_ids)\n",
    "\n",
    "    invalid_sku_count = len(invalid_sku_ids)\n",
    "    total_sku_count = len(df_inventory['sku_id'].unique())\n",
    "\n",
    "    print(red_color + 'Total SKUs: {}'.format(total_sku_count) + reset_color)\n",
    "    print(red_color + 'Number of invalid SKUs: {}'.format(invalid_sku_count) + reset_color)\n",
    "\n",
    "    invalid_sku_percentage = (invalid_sku_count / total_sku_count) * 100\n",
    "    print(red_color + 'Percentage of invalid SKUs from total SKUs: {:.2f}%'.format(invalid_sku_percentage) + reset_color)\n",
    "\n",
    "else:\n",
    "    print(green_color + \"All SKU IDs in df_inventory exist in the df_catalog\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d7950-5671-4ca7-9e91-e8cd96709a59",
   "metadata": {},
   "source": [
    "## Locations Logical Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae81be0-80cd-4df6-8e82-7d260d2f6070",
   "metadata": {},
   "source": [
    "##### **Location ID is a unique value across all rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6eb9e7e-5798-456a-a480-6cfd092365d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mNo ID duplication found in the Locations file\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert not df_locations['id'].duplicated().any()\n",
    "    print(green_color + 'No ID duplication found in the Locations file' + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Duplicate IDs found in the 'id' column\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173e5b8-838c-4f7b-a2eb-c08fae3c1a1c",
   "metadata": {},
   "source": [
    "##### **There is at least 1 location from type “store”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76b678ec-e1d1-4fe6-b7aa-341d5a10302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAt least one location of type 'store' exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_locations['type'] == 'store').any()\n",
    "    print(green_color + \"At least one location of type 'store' exists\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"No locations of type 'store' found\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ef67e-3d6e-45cd-b214-e7db385c4ba2",
   "metadata": {},
   "source": [
    "##### **There is at least 1 location from type “warehouse”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1072755f-81cf-4a29-96e9-1b7e637c3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAt least one location of type 'warehouse' exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_locations['type'] == 'warehouse').any()\n",
    "    print(green_color + \"At least one location of type 'warehouse' exists\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"No locations of type 'warehouse' found\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822c2e1-5ff0-45d2-acf8-3e505c93c4ee",
   "metadata": {},
   "source": [
    "##### **All the location types are from the optional values list (wh/store/plant/supplier/client/unknown)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cef8e19f-573c-477f-884b-63f5ee94e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll location types are from the optional values list\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "optional_values = {'warehouse', 'store', 'plant', 'supplier', 'client', 'unknown','outlet','ecommerce'}\n",
    "location_types = set(df_locations['type'].unique())\n",
    "invalid_types = location_types - optional_values\n",
    "\n",
    "try:\n",
    "    assert location_types.issubset(optional_values)\n",
    "    print(green_color + \"All location types are from the optional values list\" + reset_color)\n",
    "except:\n",
    "    if invalid_types:\n",
    "        print(red_color + \"Invalid location types found:\" + reset_color)\n",
    "        print(invalid_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e9537-df29-4d1c-b82b-78b9233b8643",
   "metadata": {},
   "source": [
    "##### **At least 1 location is not on avoid replenishment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aeecdb86-68a2-4ce1-8532-9050a24e5b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mNon mandatory column validation\u001b[0m\n",
      "\u001b[91mAll locations are on avoid replenishment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_locations['avoid_replenishment'] == 0).any()\n",
    "    print(green_color + 'At least 1 location is not on avoid replenishment' + reset_color)\n",
    "except: \n",
    "    print(red_color + \"Non mandatory column validation\" + reset_color)\n",
    "    print(red_color + 'All locations are on avoid replenishment' + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9aeff-34fb-4be3-9a6c-a459dbeac8df",
   "metadata": {},
   "source": [
    "## Transactions Logical Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99a9b4-dac7-48ff-908c-5ac02152e8e0",
   "metadata": {},
   "source": [
    "##### **Transaction ID is a unique value across all rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8b41109-1b73-40da-9ce5-450d812ed43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTransaction ID is unique across all rows\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert not df_transactions['id'].duplicated().any()\n",
    "    print(green_color + \"Transaction ID is unique across all rows\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Transaction ID is not unique\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e23fcc-41db-4159-8970-dea72d0e9e19",
   "metadata": {},
   "source": [
    "##### **Source location is different from the target location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebc167c8-0b56-4687-9466-0221f13ddb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mSource location is the same as the target location\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert (df_transactions['source_location_id'].ne(df_transactions['target_location_id'])).all()\n",
    "    print(green_color + \"Source location is different from the target location in all rows\" + reset_color)\n",
    "except:\n",
    "    print(red_color + \"Source location is the same as the target location\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a04382-4fb5-4cd9-bb4a-a079489b08a9",
   "metadata": {},
   "source": [
    "##### **Source location OR Target location exist as a known location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0683eec5-fec0-4599-9047-980244ab6325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll source and target locations exist as known locations\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "known_location_ids = set(df_locations['id'].unique())\n",
    "invalid_locations = ~(df_transactions['source_location_id'].isin(known_location_ids) |\n",
    "                     df_transactions['target_location_id'].isin(known_location_ids))\n",
    "\n",
    "invalid_source_locations = df_transactions.loc[invalid_locations, 'source_location_id']\n",
    "invalid_target_locations = df_transactions.loc[invalid_locations, 'target_location_id']\n",
    "\n",
    "if invalid_locations.any():\n",
    "    if invalid_source_locations.any():\n",
    "        print(red_color + \"Invalid source locations:\" + reset_color)\n",
    "        print(invalid_source_locations)\n",
    "    if invalid_target_locations.any():\n",
    "        print(red_color + \"Invalid target locations:\" + reset_color)\n",
    "        print(invalid_target_locations)\n",
    "else:\n",
    "    print(green_color + \"All source and target locations exist as known locations\" + reset_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0fc15-55cf-48fb-8865-22a907e8d9f6",
   "metadata": {},
   "source": [
    "##### **All SKU_ids exist in the catalog**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59c67db1-0bcd-4101-8419-298f96ad3ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mInvalid SKU IDs found in transactions:\u001b[0m\n",
      "['0AD00259NAT2A']\n",
      "\u001b[91mTotal SKUs: 1\u001b[0m\n",
      "\u001b[91mNumber of invalid SKUs: 1\u001b[0m\n",
      "\u001b[91mPercentage of invalid SKUs from total SKUs: 100.00%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "invalid_sku_ids = df_transactions[~df_transactions['sku_id'].isin(df_catalog['id'])]['sku_id'].unique()\n",
    "\n",
    "if invalid_sku_ids.any():\n",
    "    print(red_color + \"Invalid SKU IDs found in transactions:\" + reset_color)\n",
    "    print(invalid_sku_ids)\n",
    "\n",
    "    invalid_sku_count = len(invalid_sku_ids)\n",
    "    total_sku_count = len(df_transactions['sku_id'].unique())\n",
    "\n",
    "    print(red_color + 'Total SKUs: {}'.format(total_sku_count) + reset_color)\n",
    "    print(red_color + 'Number of invalid SKUs: {}'.format(invalid_sku_count) + reset_color)\n",
    "\n",
    "    invalid_sku_percentage = (invalid_sku_count / total_sku_count) * 100\n",
    "    print(red_color + 'Percentage of invalid SKUs from total SKUs: {:.2f}%'.format(invalid_sku_percentage) + reset_color)\n",
    "\n",
    "else:\n",
    "    print(green_color + \"All SKU IDs in transactions exist in the df_catalog\" + reset_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c144834f-4f86-4644-a795-44a3a5fe336a",
   "metadata": {},
   "source": [
    "##### **SKU_id exist in the Source location OR Target location**\n",
    "\n",
    "Checks if the SKU_id - target_location_id or SKU_id - source_location_id combinations exists in the df_inventory, if both of them missing - raise and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "267e032c-d654-4eca-9057-76222797fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mSKUs for which both SKU_id - target_location_id and SKU_id - source_location_id don't exist in df_inventory:\u001b[0m\n",
      "            sku_id source_location_id target_location_id\n",
      "0    0AD00259NAT2A                009                009\n",
      "1    0AD00259NAT2A                161                161\n",
      "2    0AD00259NAT2A             H0LFT5                130\n",
      "3    0AD00259NAT2A                157                157\n",
      "4    0AD00259NAT2A                009                009\n",
      "..             ...                ...                ...\n",
      "995  0AD00259NAT2A                057                 00\n",
      "996  0AD00259NAT2A                124                 00\n",
      "997  0AD00259NAT2A                009                 00\n",
      "998  0AD00259NAT2A                021                021\n",
      "999  0AD00259NAT2A                054                054\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "inventory_sku_location_combinations = set(zip(df_inventory['sku_id'], df_inventory['location_id']))\n",
    "\n",
    "missing_combinations = []\n",
    "\n",
    "for _, row in df_transactions.iterrows():\n",
    "    sku = row['sku_id']\n",
    "    target_location = row['target_location_id']\n",
    "    source_location = row['source_location_id']\n",
    "    \n",
    "    if (sku, target_location) not in inventory_sku_location_combinations and (sku, source_location) not in inventory_sku_location_combinations:\n",
    "        missing_combinations.append((sku, target_location, source_location))\n",
    "\n",
    "if len(missing_combinations) > 0:\n",
    "    missing_df = pd.DataFrame(missing_combinations, columns=['sku_id', 'source_location_id', 'target_location_id'])\n",
    "    print(red_color + \"SKUs for which both SKU_id - target_location_id and SKU_id - source_location_id don't exist in df_inventory:\" + reset_color)\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(green_color + \"All SKUs have either SKU_id - target_location_id or SKU_id - source_location_id combinations in df_inventory\" + reset_color)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
